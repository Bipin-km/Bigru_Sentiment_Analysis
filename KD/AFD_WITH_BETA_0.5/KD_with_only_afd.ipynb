{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10623654,"sourceType":"datasetVersion","datasetId":6577794},{"sourceId":245983,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":210196,"modelId":231891},{"sourceId":259187,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":221562,"modelId":243340},{"sourceId":264279,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":226061,"modelId":247836}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-21T16:14:52.439479Z","iopub.execute_input":"2025-02-21T16:14:52.439807Z","iopub.status.idle":"2025-02-21T16:14:53.386860Z","shell.execute_reply.started":"2025-02-21T16:14:52.439781Z","shell.execute_reply":"2025-02-21T16:14:53.386077Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/gru/keras/default/1/sentiment_analysis_model.h5\n/kaggle/input/amazon-dataset/data.npz\n/kaggle/input/kd/keras/default/1/student_model_final__kd.h5\n/kaggle/input/emb/keras/default/1/fully_pruned_model_latest.h5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras import layers, models, losses, optimizers\nfrom tensorflow.keras.models import load_model\nfrom tqdm import tqdm  # Import tqdm\n\n# -----------------------------------------------------------------------------\n# 2. Data Loading and Preprocessing\n# -----------------------------------------------------------------------------\ndata = np.load(\"/kaggle/input/amazon-dataset/data.npz\")\nX_train_np, y_train_np = data[\"X_train\"], data[\"y_train\"]\nX_val_np, y_val_np = data[\"X_val\"], data[\"y_val\"]\nX_test_np, y_test_np = data[\"X_test\"], data[\"y_test\"]\n\nX_train = tf.convert_to_tensor(X_train_np, dtype=tf.int32)\ny_train = tf.convert_to_tensor(y_train_np, dtype=tf.float32)\nX_val = tf.convert_to_tensor(X_val_np, dtype=tf.int32)\ny_val = tf.convert_to_tensor(y_val_np, dtype=tf.float32)\nX_test = tf.convert_to_tensor(X_test_np, dtype=tf.int32)\ny_test = tf.convert_to_tensor(y_test_np, dtype=tf.float32)\n\nbatch_size = 1024 # Reduced batch size for single GPU\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).repeat().prefetch(tf.data.AUTOTUNE)\nval_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n# -----------------------------------------------------------------------------\n# 3. Load Models (Teacher and Pruned Student with Integrated Mapping Layers)\n# -----------------------------------------------------------------------------\n# -----------------------------------------------------------------------------\n# 3. Load Models (Teacher and Pruned Student)\n# -----------------------------------------------------------------------------\n# Load the models\nteacher_model = load_model('/kaggle/input/gru/keras/default/1/sentiment_analysis_model.h5')\noriginal_student = load_model('/kaggle/input/emb/keras/default/1/fully_pruned_model_latest.h5')\n\n# Define the input layer, matching the original student input shape\ninputs = tf.keras.Input(shape=(X_train.shape[1],), dtype=tf.int32, name='input_layer')\n\n# Directly reuse layers from the original student model\nx = original_student.get_layer('embedding')(inputs)  # Embedding layer\n\n# First Bidirectional GRU layer\nx = original_student.get_layer('bidirectional')(x)\n\n# Second Bidirectional GRU layer\nx = original_student.get_layer('bidirectional_1')(x)\n\n# Flatten the output to pass it to the dense layers\nx = original_student.get_layer('flatten')(x)\n\n# Apply dropout after flattening\nx = original_student.get_layer('dropout')(x)\n\n# First Dense layer\nx = original_student.get_layer('dense')(x)\n\n# Apply dropout after the first dense layer\nx = original_student.get_layer('dropout_1')(x)\n\n# Second Dense layer\nx = original_student.get_layer('dense_1')(x)\n\n# Final output layer (single output for binary classification)\noutputs = original_student.get_layer('dense_2')(x)\n\n# Create the new student model that should match the original model exactly\nstudent_model = tf.keras.Model(inputs=inputs, outputs=outputs, name='student_with_same_architecture')\n\n# Print out the summary to verify the architecture\nstudent_model.summary()\n\n\nteacher_dense_map_bigru1 = layers.Dense(64, name='teacher_mapping_bigru1')\nteacher_dense_map_bigru2 = layers.Dense(128, name='teacher_mapping_bigru2')\n\nstudent_dense_map_bigru1 = layers.Dense(64, name='student_mapping_bigru1')\nstudent_dense_map_bigru2 = layers.Dense(128, name='student_mapping_bigru2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T16:14:55.467137Z","iopub.execute_input":"2025-02-21T16:14:55.467642Z","iopub.status.idle":"2025-02-21T16:15:43.556462Z","shell.execute_reply.started":"2025-02-21T16:14:55.467612Z","shell.execute_reply":"2025-02-21T16:15:43.555527Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"student_with_same_architecture\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"student_with_same_architecture\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m1,920,000\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m170\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m49,920\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m74,496\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920,000</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,920</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,069,249\u001b[0m (7.89 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,069,249</span> (7.89 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,069,249\u001b[0m (7.89 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,069,249</span> (7.89 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------------------------------------------------------\n# 5. Feature extraction functions (Teacher and Student)\n# -----------------------------------------------------------------------------\ndef get_teacher_features(images):\n    embedding_output = teacher_model.get_layer('embedding')(images)\n    bigru1_output = teacher_model.get_layer('bidirectional')(embedding_output)\n    t_feat1 = teacher_dense_map_bigru1(bigru1_output)\n\n    bigru2_input = t_feat1\n    bigru2_output = teacher_model.get_layer('bidirectional_1')(bigru2_input)\n    t_feat2 = teacher_dense_map_bigru2(bigru2_output)\n    return [t_feat1, t_feat2]\n\ndef get_student_features(images):\n    embedding_output = student_model.get_layer('embedding')(images)\n    bigru1_output = student_model.get_layer('bidirectional')(embedding_output)\n    s_feat1 = student_dense_map_bigru1(bigru1_output)\n\n    bigru2_input = s_feat1\n    bigru2_output = student_model.get_layer('bidirectional_1')(bigru2_input)\n    s_feat2 = student_dense_map_bigru2(bigru2_output)\n    return [s_feat1, s_feat2]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T16:15:43.557766Z","iopub.execute_input":"2025-02-21T16:15:43.558522Z","iopub.status.idle":"2025-02-21T16:15:43.563617Z","shell.execute_reply.started":"2025-02-21T16:15:43.558491Z","shell.execute_reply":"2025-02-21T16:15:43.562811Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# -----------------------------------------------------------------------------\n# 6. Loss Functions and Attention-based Feature Distillation (AFD)\n# -----------------------------------------------------------------------------\nbce_loss = losses.BinaryCrossentropy(from_logits=False)\nmse_loss = losses.MeanSquaredError()\n\ndef attention_distillation_loss(teacher_features, student_features):\n    teacher_query = teacher_features  # Treat teacher features as queries\n    student_key = student_features  # Treat student features as keys\n    \n    d_k = tf.cast(tf.shape(student_key)[-1], tf.float32)  # Feature dimension\n    scale = tf.sqrt(d_k) + 1e-8  # Scaling factor to stabilize attention\n    attn_scores = tf.matmul(teacher_query, student_key, transpose_b=True) / scale  # Attention scores (query x key^T)\n    \n    attn_scores = tf.clip_by_value(attn_scores, -50.0, 50.0)  # Clip extreme values\n    attn_weights = tf.nn.softmax(attn_scores, axis=-1)  # Softmax to get the attention weights\n    \n    attn_output = tf.matmul(attn_weights, student_features)  # Weighted student features\n    return mse_loss(teacher_features, attn_output)\n\ndef distillation_loss(teacher_out, student_out, teacher_feats, student_feats, labels, beta):\n    feat_loss1 = attention_distillation_loss(teacher_feats[0], student_feats[0])\n    feat_loss2 = mse_loss(teacher_feats[1], student_feats[1])\n    hard_loss = bce_loss(labels, student_out)\n    return hard_loss + beta * (feat_loss1 + feat_loss2) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T16:15:43.565146Z","iopub.execute_input":"2025-02-21T16:15:43.565395Z","iopub.status.idle":"2025-02-21T16:15:43.597910Z","shell.execute_reply.started":"2025-02-21T16:15:43.565376Z","shell.execute_reply":"2025-02-21T16:15:43.597124Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# -----------------------------------------------------------------------------\n# 7. Training Setup\n# -----------------------------------------------------------------------------\noptimizer = optimizers.Adam(learning_rate=1e-4)\nepochs = 20\nbeta = 0.5\n\n# Create pruned_mask to identify pruned weights (weights = 0)\npruned_mask = [tf.cast(tf.abs(w) > 0, dtype=tf.float32) for w in student_model.trainable_variables]\n\ntrain_loss_metric = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\nval_loss_metric = tf.keras.metrics.Mean('val_loss', dtype=tf.float32)\nval_accuracy_metric = tf.keras.metrics.BinaryAccuracy('val_accuracy')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T16:15:43.598739Z","iopub.execute_input":"2025-02-21T16:15:43.598954Z","iopub.status.idle":"2025-02-21T16:15:43.639984Z","shell.execute_reply.started":"2025-02-21T16:15:43.598936Z","shell.execute_reply":"2025-02-21T16:15:43.639385Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Early stopping parameters\npatience = 3  # Number of epochs to wait for improvement\nmin_delta = 0.001  # Minimum change in validation loss to qualify as improvement\nbest_val_loss = float('inf')  # Track the best validation loss\nwait = 0  # Counter for epochs without improvement","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T16:15:43.640673Z","iopub.execute_input":"2025-02-21T16:15:43.640911Z","iopub.status.idle":"2025-02-21T16:15:43.644287Z","shell.execute_reply.started":"2025-02-21T16:15:43.640891Z","shell.execute_reply":"2025-02-21T16:15:43.643573Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# -----------------------------------------------------------------------------\n# 8. Training Step (Freeze Pruned Weights)\n# -----------------------------------------------------------------------------\n@tf.function\ndef train_step(images, labels):\n    labels = tf.reshape(labels, (-1, 1))\n\n    with tf.GradientTape() as tape:\n        teacher_out = teacher_model(images, training=False)\n        student_out = student_model(images, training=True)\n\n        t_feats = get_teacher_features(images)\n        s_feats = get_student_features(images)\n\n        total_loss = distillation_loss(teacher_out, student_out, t_feats, s_feats, labels, beta)\n\n    # Compute gradients\n    grads = tape.gradient(total_loss, student_model.trainable_variables)\n\n    # Mask gradients for pruned weights (freeze pruned weights)\n    masked_grads = []\n    for grad, mask in zip(grads, pruned_mask):\n        masked_grads.append(grad * mask)  # Freeze pruned weights by masking gradients\n\n    # Apply masked gradients\n    optimizer.apply_gradients(zip(masked_grads, student_model.trainable_variables))\n    train_loss_metric.update_state(total_loss)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T16:15:43.645021Z","iopub.execute_input":"2025-02-21T16:15:43.645314Z","iopub.status.idle":"2025-02-21T16:15:43.655923Z","shell.execute_reply.started":"2025-02-21T16:15:43.645287Z","shell.execute_reply":"2025-02-21T16:15:43.655263Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# -----------------------------------------------------------------------------\n# 9. Validation Step\n# -----------------------------------------------------------------------------\n@tf.function\ndef val_step(images, labels):\n    student_out = student_model(images, training=False)\n    loss = bce_loss(labels, student_out)\n    val_loss_metric.update_state(loss)\n    val_accuracy_metric.update_state(labels, student_out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T16:15:45.723941Z","iopub.execute_input":"2025-02-21T16:15:45.724253Z","iopub.status.idle":"2025-02-21T16:15:45.728889Z","shell.execute_reply.started":"2025-02-21T16:15:45.724229Z","shell.execute_reply":"2025-02-21T16:15:45.727893Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def layerwise_trainable_zero_nonzero_params(model):\n    for layer in model.layers:\n        if hasattr(layer, 'trainable_variables'):\n            for var in layer.trainable_variables:\n                total = tf.size(var).numpy()\n                zero = np.sum(var.numpy() == 0)\n                nonzero = total - zero\n                print(f\"Layer: {layer.name} | Total: {total} | Zero: {zero} | Non-Zero: {nonzero}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T16:15:48.010129Z","iopub.execute_input":"2025-02-21T16:15:48.010481Z","iopub.status.idle":"2025-02-21T16:15:48.015089Z","shell.execute_reply.started":"2025-02-21T16:15:48.010456Z","shell.execute_reply":"2025-02-21T16:15:48.014288Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# -----------------------------------------------------------------------------\n# 10. Training Loop with Early Stopping\n# -----------------------------------------------------------------------------\nnum_batches_per_epoch = len(X_train_np) // batch_size\nnum_val_batches = len(X_val_np) // batch_size  # Calculate validation batches\n\n# Training Loop\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch+1}/{epochs}\")\n\n    train_loss_metric.reset_state()  # Reset the metrics here\n    val_loss_metric.reset_state()\n    val_accuracy_metric.reset_state()\n\n    # Training loop with tqdm progress bar\n    with tqdm(total=num_batches_per_epoch, desc=\"Training\") as pbar:\n        for step, (images, labels) in enumerate(train_dataset):  # Enumerate the dataset\n            if step >= num_batches_per_epoch:  # Break the loop when it reaches the end\n                break\n            train_step(images, labels)\n            pbar.set_postfix(loss=train_loss_metric.result().numpy())\n            pbar.update(1)\n\n    # Validation loop\n    with tqdm(total=num_val_batches, desc=\"Validation\") as pbar:\n        for step, (images, labels) in enumerate(val_dataset):  # Enumerate the dataset\n            if step >= num_val_batches:  # Break the loop when it reaches the end\n                break\n            val_step(images, labels)\n            pbar.set_postfix(val_loss=val_loss_metric.result().numpy(), val_accuracy=val_accuracy_metric.result().numpy())\n            pbar.update(1)\n\n    # Get the current validation loss\n    current_val_loss = val_loss_metric.result().numpy()\n\n    # Early stopping logic\n    if current_val_loss < best_val_loss - min_delta:\n        print(f\"Validation loss improved from {best_val_loss:.4f} to {current_val_loss:.4f}\")\n        best_val_loss = current_val_loss\n        wait = 0  # Reset the wait counter\n    else:\n        wait += 1\n        print(f\"Validation loss did not improve. Patience: {wait}/{patience}\")\n\n    # Stop training if patience is exceeded\n    if wait >= patience:\n        print(f\"Early stopping triggered at epoch {epoch+1}!\")\n        break\n\n    print(f\"Training Loss: {train_loss_metric.result().numpy()}\")\n    print(f\"Validation Loss: {val_loss_metric.result().numpy()}, Validation Accuracy: {val_accuracy_metric.result().numpy()}\")\n    layerwise_trainable_zero_nonzero_params(student_model)\n# -----------------------------------------------------------------------------\n# 11. Save the Final Model\n# -----------------------------------------------------------------------------\n# Save the final student model\nstudent_model.save('/kaggle/working/student_model_final.h5')  # Save as HDF5 file\nprint(\"Model saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T16:15:48.301580Z","iopub.execute_input":"2025-02-21T16:15:48.301815Z","iopub.status.idle":"2025-02-21T18:30:53.908151Z","shell.execute_reply.started":"2025-02-21T16:15:48.301796Z","shell.execute_reply":"2025-02-21T18:30:53.907284Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 6835/6835 [32:52<00:00,  3.46it/s, loss=0.219]\nValidation: 100%|██████████| 1464/1464 [00:56<00:00, 25.75it/s, val_accuracy=0.928, val_loss=0.199]\n","output_type":"stream"},{"name":"stdout","text":"Validation loss improved from inf to 0.1986\nTraining Loss: 0.218705415725708\nValidation Loss: 0.1986151784658432, Validation Accuracy: 0.9280778765678406\nLayer: embedding | Total: 1920000 | Zero: 3392 | Non-Zero: 1916608\nLayer: bidirectional | Total: 12288 | Zero: 11505 | Non-Zero: 783\nLayer: bidirectional | Total: 12288 | Zero: 11488 | Non-Zero: 800\nLayer: bidirectional | Total: 384 | Zero: 370 | Non-Zero: 14\nLayer: bidirectional | Total: 12288 | Zero: 11346 | Non-Zero: 942\nLayer: bidirectional | Total: 12288 | Zero: 11489 | Non-Zero: 799\nLayer: bidirectional | Total: 384 | Zero: 358 | Non-Zero: 26\nLayer: bidirectional_1 | Total: 24576 | Zero: 24058 | Non-Zero: 518\nLayer: bidirectional_1 | Total: 12288 | Zero: 11971 | Non-Zero: 317\nLayer: bidirectional_1 | Total: 384 | Zero: 379 | Non-Zero: 5\nLayer: bidirectional_1 | Total: 24576 | Zero: 23691 | Non-Zero: 885\nLayer: bidirectional_1 | Total: 12288 | Zero: 11709 | Non-Zero: 579\nLayer: bidirectional_1 | Total: 384 | Zero: 358 | Non-Zero: 26\nLayer: dense | Total: 16384 | Zero: 16288 | Non-Zero: 96\nLayer: dense | Total: 128 | Zero: 127 | Non-Zero: 1\nLayer: dense_1 | Total: 8192 | Zero: 8023 | Non-Zero: 169\nLayer: dense_1 | Total: 64 | Zero: 56 | Non-Zero: 8\nLayer: dense_2 | Total: 64 | Zero: 0 | Non-Zero: 64\nLayer: dense_2 | Total: 1 | Zero: 0 | Non-Zero: 1\nEpoch 2/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 6835/6835 [32:37<00:00,  3.49it/s, loss=0.182]\nValidation: 100%|██████████| 1464/1464 [00:55<00:00, 26.46it/s, val_accuracy=0.928, val_loss=0.201]\n","output_type":"stream"},{"name":"stdout","text":"Validation loss did not improve. Patience: 1/3\nTraining Loss: 0.18198953568935394\nValidation Loss: 0.20075227320194244, Validation Accuracy: 0.9278711080551147\nLayer: embedding | Total: 1920000 | Zero: 3392 | Non-Zero: 1916608\nLayer: bidirectional | Total: 12288 | Zero: 11505 | Non-Zero: 783\nLayer: bidirectional | Total: 12288 | Zero: 11488 | Non-Zero: 800\nLayer: bidirectional | Total: 384 | Zero: 370 | Non-Zero: 14\nLayer: bidirectional | Total: 12288 | Zero: 11346 | Non-Zero: 942\nLayer: bidirectional | Total: 12288 | Zero: 11489 | Non-Zero: 799\nLayer: bidirectional | Total: 384 | Zero: 358 | Non-Zero: 26\nLayer: bidirectional_1 | Total: 24576 | Zero: 24058 | Non-Zero: 518\nLayer: bidirectional_1 | Total: 12288 | Zero: 11971 | Non-Zero: 317\nLayer: bidirectional_1 | Total: 384 | Zero: 379 | Non-Zero: 5\nLayer: bidirectional_1 | Total: 24576 | Zero: 23691 | Non-Zero: 885\nLayer: bidirectional_1 | Total: 12288 | Zero: 11709 | Non-Zero: 579\nLayer: bidirectional_1 | Total: 384 | Zero: 358 | Non-Zero: 26\nLayer: dense | Total: 16384 | Zero: 16288 | Non-Zero: 96\nLayer: dense | Total: 128 | Zero: 127 | Non-Zero: 1\nLayer: dense_1 | Total: 8192 | Zero: 8023 | Non-Zero: 169\nLayer: dense_1 | Total: 64 | Zero: 56 | Non-Zero: 8\nLayer: dense_2 | Total: 64 | Zero: 0 | Non-Zero: 64\nLayer: dense_2 | Total: 1 | Zero: 0 | Non-Zero: 1\nEpoch 3/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 6835/6835 [32:40<00:00,  3.49it/s, loss=0.174]\nValidation: 100%|██████████| 1464/1464 [01:21<00:00, 17.87it/s, val_accuracy=0.928, val_loss=0.203]\n","output_type":"stream"},{"name":"stdout","text":"Validation loss did not improve. Patience: 2/3\nTraining Loss: 0.17373375594615936\nValidation Loss: 0.20281369984149933, Validation Accuracy: 0.9275029301643372\nLayer: embedding | Total: 1920000 | Zero: 3392 | Non-Zero: 1916608\nLayer: bidirectional | Total: 12288 | Zero: 11505 | Non-Zero: 783\nLayer: bidirectional | Total: 12288 | Zero: 11488 | Non-Zero: 800\nLayer: bidirectional | Total: 384 | Zero: 370 | Non-Zero: 14\nLayer: bidirectional | Total: 12288 | Zero: 11346 | Non-Zero: 942\nLayer: bidirectional | Total: 12288 | Zero: 11489 | Non-Zero: 799\nLayer: bidirectional | Total: 384 | Zero: 358 | Non-Zero: 26\nLayer: bidirectional_1 | Total: 24576 | Zero: 24058 | Non-Zero: 518\nLayer: bidirectional_1 | Total: 12288 | Zero: 11971 | Non-Zero: 317\nLayer: bidirectional_1 | Total: 384 | Zero: 379 | Non-Zero: 5\nLayer: bidirectional_1 | Total: 24576 | Zero: 23691 | Non-Zero: 885\nLayer: bidirectional_1 | Total: 12288 | Zero: 11709 | Non-Zero: 579\nLayer: bidirectional_1 | Total: 384 | Zero: 358 | Non-Zero: 26\nLayer: dense | Total: 16384 | Zero: 16288 | Non-Zero: 96\nLayer: dense | Total: 128 | Zero: 127 | Non-Zero: 1\nLayer: dense_1 | Total: 8192 | Zero: 8023 | Non-Zero: 169\nLayer: dense_1 | Total: 64 | Zero: 56 | Non-Zero: 8\nLayer: dense_2 | Total: 64 | Zero: 0 | Non-Zero: 64\nLayer: dense_2 | Total: 1 | Zero: 0 | Non-Zero: 1\nEpoch 4/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 6835/6835 [32:44<00:00,  3.48it/s, loss=0.169]\nValidation: 100%|██████████| 1464/1464 [00:56<00:00, 25.86it/s, val_accuracy=0.927, val_loss=0.205]\n","output_type":"stream"},{"name":"stdout","text":"Validation loss did not improve. Patience: 3/3\nEarly stopping triggered at epoch 4!\nModel saved successfully!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"st_ml = tf.keras.models.load_model('/kaggle/working/student_model_final.h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T18:32:31.980344Z","iopub.execute_input":"2025-02-21T18:32:31.980660Z","iopub.status.idle":"2025-02-21T18:32:32.114285Z","shell.execute_reply.started":"2025-02-21T18:32:31.980637Z","shell.execute_reply":"2025-02-21T18:32:32.113612Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"st_ml.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\ntest_loss, test_accuracy = st_ml.evaluate(X_test, y_test, verbose=1)\n\nprint(f\"Testing Loss: {test_loss:.4f}\")\nprint(f\"Testing Accuracy: {test_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T18:32:43.236139Z","iopub.execute_input":"2025-02-21T18:32:43.236452Z","iopub.status.idle":"2025-02-21T18:42:35.668584Z","shell.execute_reply.started":"2025-02-21T18:32:43.236428Z","shell.execute_reply":"2025-02-21T18:42:35.667825Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m46875/46875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m592s\u001b[0m 13ms/step - accuracy: 0.9275 - loss: 0.2051\nTesting Loss: 0.2054\nTesting Accuracy: 0.9273\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"st_ml.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nval_loss, val_accuracy = st_ml.evaluate(X_val, y_val, verbose=1)\n\nprint(f\"Validation Loss: {val_loss:.4f}\")\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T18:42:35.669781Z","iopub.execute_input":"2025-02-21T18:42:35.670102Z","iopub.status.idle":"2025-02-21T18:52:35.623410Z","shell.execute_reply.started":"2025-02-21T18:42:35.670069Z","shell.execute_reply":"2025-02-21T18:52:35.622531Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m46875/46875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m600s\u001b[0m 13ms/step - accuracy: 0.9278 - loss: 0.2050\nValidation Loss: 0.2055\nValidation Accuracy: 0.9273\n","output_type":"stream"}],"execution_count":13}]}